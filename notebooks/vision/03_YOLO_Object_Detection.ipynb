{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9QpT-IUeZkd"
      },
      "source": [
        "## 1. Install and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LFxGEbTVawnf"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "import os, glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpCROV-6eqP0"
      },
      "source": [
        "## 2. Set up paths to your models and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vaVD3fHoetkS"
      },
      "outputs": [],
      "source": [
        "# === EDIT THESE PATHS ===\n",
        "\n",
        "# YOLO weight files (best.pt) for each model\n",
        "baseline_weights      = \"Object Detection Models/Baseline Model/weights/best.pt\"\n",
        "larger_dataset_weights = \"Object Detection Models/Larger Model/weights/best.pt\"\n",
        "transformed_weights    = \"Object Detection Models/Larger Transformed Model/weights/best.pt\"\n",
        "\n",
        "# === Folder containing unseen fridge images you want to test ===\n",
        "test_images = \"Object Detection Models/Unseen Fridge Pics\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ufivHXafk1T"
      },
      "source": [
        "## 3. Evaluate each model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ibKjzZx0fkgJ"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"baseline\": baseline_weights,\n",
        "    \"larger\": larger_dataset_weights,\n",
        "    \"transformed\": transformed_weights,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMwmgVbOgBzB"
      },
      "source": [
        "## 4. Crop detections and save them for the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hfDyrFDIf-h4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Running model on unseen images: baseline ===\n",
            "\n",
            "image 1/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.16_6461b37d.jpg: 640x480 16 Ingredientss, 119.4ms\n",
            "image 2/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_50a2e48a.jpg: 640x480 16 Ingredientss, 79.1ms\n",
            "image 3/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_65d69e83.jpg: 640x480 10 Ingredientss, 108.2ms\n",
            "image 4/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_e158e6e0.jpg: 640x480 10 Ingredientss, 88.7ms\n",
            "image 5/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.48_48c8af1c.jpg: 640x480 20 Ingredientss, 95.8ms\n",
            "image 6/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.48_75b55e74.jpg: 640x480 15 Ingredientss, 88.9ms\n",
            "image 7/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_04be1edc.jpg: 640x480 13 Ingredientss, 89.8ms\n",
            "image 8/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_05ec1042.jpg: 640x480 20 Ingredientss, 86.9ms\n",
            "image 9/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_3064390a.jpg: 640x480 21 Ingredientss, 82.9ms\n",
            "image 10/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_66180257.jpg: 640x480 9 Ingredientss, 81.1ms\n",
            "image 11/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_a1369e5d.jpg: 640x480 15 Ingredientss, 88.4ms\n",
            "image 12/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_ca916bf7.jpg: 640x480 13 Ingredientss, 81.3ms\n",
            "image 13/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_e0fe0235.jpg: 640x480 26 Ingredientss, 86.0ms\n",
            "image 14/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_e5dea645.jpg: 640x480 20 Ingredientss, 88.1ms\n",
            "image 15/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_f46aa169.jpg: 640x480 16 Ingredientss, 88.0ms\n",
            "image 16/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_222c6c7b.jpg: 640x480 15 Ingredientss, 80.9ms\n",
            "image 17/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_5187ca21.jpg: 640x480 16 Ingredientss, 83.7ms\n",
            "image 18/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_8c9b6022.jpg: 640x480 11 Ingredientss, 79.6ms\n",
            "image 19/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_9a887d76.jpg: 640x480 9 Ingredientss, 83.2ms\n",
            "image 20/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_f7aace8d.jpg: 640x480 14 Ingredientss, 89.3ms\n",
            "image 21/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_15694d51.jpg: 640x480 9 Ingredientss, 93.9ms\n",
            "image 22/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_3d00669e.jpg: 640x480 5 Ingredientss, 87.2ms\n",
            "image 23/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_8a94094e.jpg: 640x480 6 Ingredientss, 119.8ms\n",
            "image 24/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_bb22f571.jpg: 640x480 8 Ingredientss, 89.0ms\n",
            "image 25/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.42_03692b11.jpg: 640x480 8 Ingredientss, 94.6ms\n",
            "image 26/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.42_71676f56.jpg: 640x480 11 Ingredientss, 83.1ms\n",
            "Speed: 2.5ms preprocess, 89.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/crop_results/baseline\u001b[0m\n",
            "\n",
            "=== Running model on unseen images: larger ===\n",
            "\n",
            "image 1/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.16_6461b37d.jpg: 640x480 12 Ingredientss, 79.8ms\n",
            "image 2/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_50a2e48a.jpg: 640x480 14 Ingredientss, 70.4ms\n",
            "image 3/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_65d69e83.jpg: 640x480 12 Ingredientss, 78.2ms\n",
            "image 4/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_e158e6e0.jpg: 640x480 12 Ingredientss, 77.3ms\n",
            "image 5/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.48_48c8af1c.jpg: 640x480 9 Ingredientss, 76.5ms\n",
            "image 6/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.48_75b55e74.jpg: 640x480 18 Ingredientss, 75.9ms\n",
            "image 7/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_04be1edc.jpg: 640x480 10 Ingredientss, 79.9ms\n",
            "image 8/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_05ec1042.jpg: 640x480 29 Ingredientss, 74.1ms\n",
            "image 9/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_3064390a.jpg: 640x480 22 Ingredientss, 95.7ms\n",
            "image 10/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_66180257.jpg: 640x480 7 Ingredientss, 74.8ms\n",
            "image 11/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_a1369e5d.jpg: 640x480 12 Ingredientss, 82.2ms\n",
            "image 12/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_ca916bf7.jpg: 640x480 17 Ingredientss, 74.5ms\n",
            "image 13/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_e0fe0235.jpg: 640x480 22 Ingredientss, 76.1ms\n",
            "image 14/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_e5dea645.jpg: 640x480 16 Ingredientss, 76.1ms\n",
            "image 15/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_f46aa169.jpg: 640x480 11 Ingredientss, 87.1ms\n",
            "image 16/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_222c6c7b.jpg: 640x480 10 Ingredientss, 74.8ms\n",
            "image 17/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_5187ca21.jpg: 640x480 19 Ingredientss, 79.0ms\n",
            "image 18/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_8c9b6022.jpg: 640x480 7 Ingredientss, 78.8ms\n",
            "image 19/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_9a887d76.jpg: 640x480 16 Ingredientss, 78.4ms\n",
            "image 20/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_f7aace8d.jpg: 640x480 17 Ingredientss, 75.5ms\n",
            "image 21/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_15694d51.jpg: 640x480 8 Ingredientss, 74.6ms\n",
            "image 22/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_3d00669e.jpg: 640x480 2 Ingredientss, 78.3ms\n",
            "image 23/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_8a94094e.jpg: 640x480 7 Ingredientss, 74.2ms\n",
            "image 24/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_bb22f571.jpg: 640x480 7 Ingredientss, 82.5ms\n",
            "image 25/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.42_03692b11.jpg: 640x480 4 Ingredientss, 75.1ms\n",
            "image 26/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.42_71676f56.jpg: 640x480 10 Ingredientss, 79.8ms\n",
            "Speed: 2.1ms preprocess, 78.1ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/crop_results/larger\u001b[0m\n",
            "\n",
            "=== Running model on unseen images: transformed ===\n",
            "\n",
            "image 1/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.16_6461b37d.jpg: 640x480 11 Ingredientss, 77.2ms\n",
            "image 2/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_50a2e48a.jpg: 640x480 12 Ingredientss, 75.3ms\n",
            "image 3/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_65d69e83.jpg: 640x480 11 Ingredientss, 76.8ms\n",
            "image 4/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-08 at 15.39.18_e158e6e0.jpg: 640x480 11 Ingredientss, 72.9ms\n",
            "image 5/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.48_48c8af1c.jpg: 640x480 6 Ingredientss, 82.2ms\n",
            "image 6/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.48_75b55e74.jpg: 640x480 22 Ingredientss, 76.3ms\n",
            "image 7/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_04be1edc.jpg: 640x480 11 Ingredientss, 79.6ms\n",
            "image 8/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_05ec1042.jpg: 640x480 17 Ingredientss, 75.6ms\n",
            "image 9/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_3064390a.jpg: 640x480 15 Ingredientss, 70.1ms\n",
            "image 10/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_66180257.jpg: 640x480 18 Ingredientss, 75.0ms\n",
            "image 11/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_a1369e5d.jpg: 640x480 13 Ingredientss, 81.2ms\n",
            "image 12/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_ca916bf7.jpg: 640x480 13 Ingredientss, 74.5ms\n",
            "image 13/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_e0fe0235.jpg: 640x480 17 Ingredientss, 83.8ms\n",
            "image 14/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_e5dea645.jpg: 640x480 13 Ingredientss, 82.4ms\n",
            "image 15/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.14.49_f46aa169.jpg: 640x480 17 Ingredientss, 88.0ms\n",
            "image 16/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_222c6c7b.jpg: 640x480 20 Ingredientss, 78.3ms\n",
            "image 17/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_5187ca21.jpg: 640x480 19 Ingredientss, 81.2ms\n",
            "image 18/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_8c9b6022.jpg: 640x480 15 Ingredientss, 77.7ms\n",
            "image 19/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_9a887d76.jpg: 640x480 11 Ingredientss, 80.8ms\n",
            "image 20/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-19 at 21.24.50_f7aace8d.jpg: 640x480 13 Ingredientss, 79.7ms\n",
            "image 21/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_15694d51.jpg: 640x480 10 Ingredientss, 79.5ms\n",
            "image 22/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_3d00669e.jpg: 640x480 6 Ingredientss, 82.5ms\n",
            "image 23/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_8a94094e.jpg: 640x480 8 Ingredientss, 77.7ms\n",
            "image 24/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.41_bb22f571.jpg: 640x480 6 Ingredientss, 77.0ms\n",
            "image 25/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.42_03692b11.jpg: 640x480 3 Ingredientss, 75.4ms\n",
            "image 26/26 /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/Object Detection Models/Unseen Fridge Pics/WhatsApp Image 2025-11-20 at 14.20.42_71676f56.jpg: 640x480 11 Ingredientss, 76.3ms\n",
            "Speed: 2.3ms preprocess, 78.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1m/Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/crop_results/transformed\u001b[0m\n",
            "\n",
            "All crops saved under: /Users/riyaa/Desktop/UCL_Year3/Term1/Deep Learning/Coursework/Object_Detect_Code/crop_results\n"
          ]
        }
      ],
      "source": [
        "crop_root = \"crop_results\"\n",
        "os.makedirs(crop_root, exist_ok=True)\n",
        "\n",
        "for name, weights in models.items():\n",
        "    print(f\"\\n=== Running model on unseen images: {name} ===\")\n",
        "    model = YOLO(weights)\n",
        "\n",
        "    results = model.predict(\n",
        "        source=test_images,\n",
        "        imgsz=640,\n",
        "        conf=0.5,\n",
        "        iou=0.5,\n",
        "        save=True,            # save full annotated images\n",
        "        save_crop=True,       # saves individual object crops\n",
        "        project=crop_root,\n",
        "        name=name,\n",
        "        exist_ok=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "print(\"\\nAll crops saved under:\", os.path.abspath(crop_root))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
